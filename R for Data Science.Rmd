---
output:
  html_document: default
  pdf_document: default
  word_document: default
---


# Chapter1: Data Visualization with gglopt2
## First steps

mpg dataset:
- model: model name
- displ: engine displacement, in litres
- year: year of manufacture
- cyl: number of cylinders
- trans: type of transmission
- drv: f = front-wheel drive, r = rear wheel drive, 4 = 4wd
- cty: city miles per gallon
- hwy: highway miles per gallon
- fl: fuel type
- class: "type" of car

```{r}
library(tidyverse)
?mpg
head(mpg)
dim(mpg)
#mpg - #drv: front-wheel drive, r:rear wheel drive, 4: 4wd

ggplot(data=mpg)+
  geom_point(mapping=aes(x=displ,y=hwy))

ggplot(data=mpg)+
  geom_point(mapping=aes(x=hwy,y=cyl))
plot(mpg$hwy,mpg$cyl)

# geom_point
ggplot(data=mpg)+
  geom_point(mapping=aes(x=class,y=drv))
```

## Aesthetic mappings 
We can add a third variable, like class, to a two-dimensioal scatterplot by mapping it to an aesthetic.
```{r}
library(ggplot2)
# color
ggplot(data=mpg)+
  geom_point(mapping=aes(x=displ,y=hwy,color=class))
# size
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy,size=class))
# alpha - transparency
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy,shape=class))
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy,alpha=class))
```

## Exercises 
```{r ggplot exercise}
#1.ggplot visualization
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy),color='blue')

#2. which variables in mpg are categorical? Which variables are continuous
head(mpg)
# categoirical: model,manufacturer,trans,drv,fl,class
# 

#3. Map a continuous variable to color, size, and shape. How do these aesthetics behave differently for categorical vs. continuous variables?
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy,color=cty))
#ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy,shape=cty))
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy,size=cty))

#4 What happens if you map the same variable to multiple aesthetics?
ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, colour = cty, size = cty),alpha=0.5,bins=0.5)

#5 What does the stroke aesthetic do? What shapes does it work with? (Hint: use ?geom_point)
#Answer: Stroke controls the width of the border of certain shapes. Those shapes which have borders are the only ones that stroke can alter.

#6 What happens if you map an aesthetic to something other than a variable name, like aes(colour = displ < 5)?
ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, colour = displ < 5))

#ggplot turns displ < 5 into a boolean (or dummy) variable on the fly and maps that T or F to the colour argument.

```

## Facets
One way to add additional variables is with aesthetics. Another way, particularty useful for categorical variables, is to split the plot into facets, subplots that each display one subset of the data.
```{r facet_wrap, facet_grid}
library(ggplot2)

# facet wrap
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy))+facet_wrap(~class,nrow=2)

# facet_grid: combination of two variables
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy))+facet_grid(drv~cyl)
```

## Facet Exercise
1. What happens if you facet on a continuous variable?
- We can still plot it anyway.

```{r facet on continuous variable}
head(mpg)
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy))+facet_wrap(~cty)
```

2. What do the emplty cells in a lot with facet_grid(drv~cyl) mean? How do they relate to this plot?
- There are combinations where there are no data points.
```{r facet_grid}
ggplot(data=mpg)+geom_point(mapping=aes(x=drv,y=cyl))+facet_grid(drv~cyl)
```

3. What plots does the following code make? What does.do?
- The dot controls whether the facetting will be done row or column wise. For example,`facet_grid(. ~ drv)` will sue drv as rows while `facet_grid(.~drv)` will use it as columns. `facet_grid(~drv)` will do the same as the columns wise facetting but `facet_grid(drv~)` won't because a formula object needs to have something after the ~. 


```{r dot in facet_grid}
# drv~ row divide
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy))+facet_grid(drv~.)
# column divide by cyl
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy))+facet_grid(.~cyl)
```

4 . Take the first faceted plot in this section.
```{r }
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy))+facet_wrap(~class,nrow=2)
```

What are the advantages of using faceting instead of the colour aesthetic? What are the disadvantages?
- facetting is better when we want to pay attention to particular facets alone while using the color aesthetic is better for within group patterss.

5. Read ?facet_warp. What does nrow do? What does ncol do? What other options control the layout of the individual panels? why doesn't facet_grid have nrow and ncolu variables?
- nrow controls the number of rows for the total number of facets whereas ncol controls the number of columns. Other options can control interesting parameters. For example, scales can control whether each plot has its own y axis with scales = "free", as in allow the axes to be free. The function also has the labeller option to change the names of each facet and other options like strip.position for the position of the facets labels. Read ?facet_wrap for more options.

## Geometric Objects

Geom is the geometrical object that a plot uses to represent data. To change the geom in the plot, change the geom function that we add to ggplot.
```{r geometric objects}
# left
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy))

# right
ggplot(data=mpg)+geom_smooth(mapping=aes(x=displ,y=hwy))
```

Every geom function in ggplot2 takes a mapping argument. However, not every aesthetic works with every geom. 
- geom_smooth() will draw a different line, with a different linetype, for each unique value of the variable that we map to linetype.
```{r geom_smooth with different linetype}
ggplot(data=mpg)+geom_smooth(mapping=aes(x=displ,y=hwy,linetype=drv))
```

ggplot provides over 30 geoms, and extension packages provide even more (refer: http://www.ggplot2-exts.org)

Many geoms like geom_smoooth(), use a single geompetric object to displya multiple rows of data. For these geoms, we can see the group aesthetic to a categorical variable to draw multiple objects.
```{r group aesthetic}
# standard
ggplot(data=mpg)+geom_smooth(mapping=aes(x=displ,y=hwy))
# group aesthetic
ggplot(data=mpg)+geom_smooth(mapping=aes(x=displ,y=hwy,group=drv))
# color aesthetic
ggplot(data=mpg)+geom_smooth(mapping=aes(x=displ,y=hwy,color=drv))
```

To display multiple geoms in the same plot, add multiple geom functions to ggplot()
```{r multiple geoms}
ggplot(data=mpg, mapping=aes(x=displ,y=hwy))+geom_point(aes(color=class))+geom_smooth()
```

We can use the same idea to specify different data for each layer.Here, our smooth line displays just a subset of the mpg dataset, the subcompact cars. The local data argument in geom_smooth() overrides the global data argument in ggplot() for that layer only.

```{r }
ggplot(data=mpg,mapping=aes(x=displ,y=hwy))+
  geom_point(mapping=aes(color=class))+
  geom_smooth(data=filter(mpg,class=='subcompact'),se=FALSE)

library(dplyr)
distinct(mpg)
```

## geometric objects exercise
1. What geom would you use to draw a line chart? A boxplot? A histogram? An area chart?
```{r geom exercise 1}
library(ggplot2)
data(package="ggplot2")

# line chart
library(magrittr)
head(mpg)
mpg %>% group_by(year) %>%
  mutate(m=mean(cty)) %>% ggplot(aes(year,m)) +
  geom_line()

# summarise() function
# mpg %>% group_by(year)%>% summarise(m=mean(cty)) %>% ggplot(aes(year,m))+geom_line()

# Boxplot
ggplot(mpg,aes(class,hwy))+geom_boxplot()

# Histogram
ggplot(mpg,aes(displ))+geom_histogram(bins=60)

# Area chart
huron <- data.frame(year=1875:1972, level=as.vector(LakeHuron))
ggplot(huron,aes(year,level))+geom_area()
```

2. Run this code in your head, and precdict what the output will look like. Then, run the code in R and check the predictions:
```{r geom exercise 2}
ggplot(mpg,mapping=aes(x=displ,y=hwy,color=drv))+
  geom_point()+geom_smooth(se=FALSE)
```

3. What does sho.legend=FALSE do? What happens if we remove it? Why do we think we used it earlier in this chapter?
`It removes the legend. It gives a cleaner plot when its clear that the grouping is done on a specific variable`

4. What does the se argument to geom_smooth() do?
`It removes the confidence interval from the smooothed line`

5. Will these two graphs look different? Why?
```{r geom exercise 5}
ggplot(mpg,aes(displ,hwy))+geom_point()+geom_smooth()

ggplot() + 
  geom_point(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_smooth(data = mpg, mapping = aes(x = displ, y = hwy))
```

6. Let's recreate the R code necessary to generate the following graphs.
```{r geom exercise 6}
# 1st.
ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  geom_smooth(se = F)

ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  geom_smooth(aes(group = drv), se = F)

# 2nd.
ggplot(mpg, aes(displ, hwy, colour = drv)) +
  geom_smooth(se = F) +
  geom_point()

ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = drv)) +
  geom_smooth(se = F)

# 3rd.
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = drv)) +
  geom_smooth(aes(linetype = drv), se = F)

# You can do this one by choosing a shape which has a border and simply colour
# the border with `colour` and the insides with `fill` (which is matched to drv).
# Then make the whole point a bit bigger with size
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(fill = drv), shape = 21, stroke = 2, colour = "white", size = 3)
```

## Statistical Transformation
Next, let's take a look at a bar chart. 

We can generally use geoms and stas interchangeably. For example, we can re-create the previous plot using stat_count() instead of geom_bar(): 
```{r statistical transformation}
library(ggplot2)
ggplot(diamonds)+stat_count(mapping=aes(x=cut))
```

Every geom has a default stat, and every stat has a default geom. This means we can typically use geoms without worrying about the underlying statistical transformation. 

### geom_bar stat="identity"
We want to override the default stat. In the following code, we change the stat of geom_bar from count to indentiy. This lets us map the height of the bars to the ra value of y variable.
```{r}
demo <- tribble(
  ~a, ~b,
  "bar_1", 20,
  "bar_2", 30,
  "bar_3", 40)

ggplot(data=demo)+
  geom_bar(aes(x=a,y=b),stat="identity")
```

### transformed variables to aesthetic
We can override the deafault mapping from transformed variables to aesthetics. For example, we want to display a bar chart of proportion, rather than count:
```{r}
ggplot(diamonds)+
  geom_bar(aes(x=cut,y=..prop..,group=1))
```

### statistical transformation
We wnt to draw greater attention to the statistical transformation in the code. we use stat_summary, which summarizes the y values for each unique x value, to draw attention to the summary that we are computing.
```{r}
ggplot(data = diamonds) + 
  stat_summary(
    mapping = aes(x = cut, y = depth),
    fun.ymin = min,
    fun.ymax = max,
    fun.y = median
  )
```

ggplot2 provides over 20 stats for you to use. Each stat is a function, so we can get help in the usual way, e.g., ?stat_bin. To see a complete list of stats, try the ggplot2 cheatsheet.

### Statistical transformation exercise
1. What is the default geom associated with stat_summary()? How could you rewrite the previous plot to use that geom function instead of the stat function?
```{r}
ggplot(data = diamonds) + 
  stat_summary(
    mapping = aes(x = cut, y = depth),
    fun.ymin = min,
    fun.ymax = max,
    fun.y = median
  )
```

`stat_summary` is associated with `geom_pointrange`.
```{r}
ggplot(diamonds)+
  geom_pointrange(aes(cut,depth,ymin=depth,ymax=depth))
```

2. What does geom_col() do? How is it different to geom_bar()?
`geom_col` leaves the data as it is. `geom_bar()` creates two variables (count and prod) and then graphs the count data on the y axis. With `geom_col` we can plot the values of any x variable against any y value.
```{r}
# For example, plotting exactly x to y values.
aggregate.data.frame(diamonds$price,list(diamonds$cut),mean,na.rm=T) %>%
  print(.)%>%
  ggplot(aes(Group.1,x))+
  geom_col()
```

3. Most geoms and stats come in pars that are almost always used in concert. Read through the documentation and make a list of all the pairs what do they have in common?

4. What variables does stat_smoooth() compute? What parameters control its hehaviour?

5. Inour proportion bar chart, we need to set group=1. Why? In other words, what is the problem with these two graphs?

- `stat_smoooth` computes the y, the predicted value of y for each x value. Also, it computes the se of that value predicted, together with the upper and lower bound of that point prediction. It can compute different methods such as `lm`,`glm`,`lowess` among others. See method in `?stat_smooth`. The statistic can be controlled with the method argument. 

We can see the values by wrapping any plot that has geom_smoooth() with ggplot_build(). 

In our porportion bar chart, we need to set group=1. Why? In other words, what is the problem with these two graphs? 

Ctl + Shift + M: %>% pipe operator

```{r}
# Each cut is treated as a searapte group that sums to 1.
ggplot(data = diamonds) +
  geom_bar(mapping = aes(x = cut, y = ..prop..))

# If you calculate it manually, it doesn't matter
m <- ggplot(data = diamonds)
m + geom_bar(aes(cut, ..count../sum(..count..)))

diamonds %>%
  count(cut) %>%
  mutate(prop = n/sum(n)) %>%
  ggplot(aes(cut, prop)) + geom_bar(stat = "identity") # or geom_col()

ggplot(diamonds, aes(cut)) + geom_bar(aes(y = ..count../sum(..count..)))

# By specifying group = 1, you treat all cut groups as 1 group.
ggplot(diamonds, aes(cut)) + geom_bar(aes(y = ..prop.., group = 1))
# and thus all the proportions are done calculate as a single group

```

## Position Adjustments
There's one more piece of magic associated with bar charts. We can color a bar chart uing either the color aesthetic, or more usefully, fill:
```{r Position adjustment - color/fill}
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut,color=cut))
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut,fill=cut))
```

Note what will happen if we map the fill aesthetic to another variable, like clarity.
```{r}
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut,fill=clarity))
```

The stacking is performed automatically bt the position adjustments specificed by the position argument. If we don't want a stacked bar chart, we can use one of three other options: "identity","dodge","fill".
- position="identity": will place each object exactly where it falls in the context of the group
```{r}
library(ggplot2)
library(magrittr)
diamonds %>% ggplot(aes(x=cut,fill=clarity)) +geom_bar(alpha=1/5,position="identity")

diamonds %>% ggplot(aes(x=cut,color=clarity))+geom_bar(fill=NA,position="identity")
```

- position="fill": works like stacking but makes each set of stacked bars the same height.
```{r}
ggplot(data=diamonds)+geom_bar(aes(x=cut,fill=clarity),position = "fill")
```

- position="dodge": places overlapping objects directly beside one another. This make it easier to compare individual values:
```{r}
diamonds %>% ggplot()+geom_bar(aes(x=cut,fill=clarity),position="dodge")
```

Overplotting: We can avoid overplotting gridding by setting the position adjustment to "jitter". 
- position="jitter" adds a small amount of random noise to each point. This spreads the points out because no two points are likely to receive the same amount of random noises. 
```{r}
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy),position="jitter")
```

## Position adjustment exercise
1. What is the problem with this plot? How could we improve it?
```{r}
ggplot(mpg,mapping=aes(x=cty,y=hwy))+geom_point(position="jitter")

# OR 
mpg %>% ggplot(aes(x=cty,y=hwy))+geom_point(alpha=0.2)+geom_jitter()
```

2. What parameters to geom_jitter() control te amount of jittering?


# Chapter 2: Workflow Basics 
## Workflow Exercise
1. Why does this code not work?
```{r}
my_variable <- 10
my_variable
```

2. Tweak each of the following R commands so that they run correctly.
```{r}
# mpg dataset
library(tidyverse)
ggplot(data=mpg)+geom_point(mapping=aes(x=displ,y=hwy))
filter(mpg,cyl==8)

# diamonds dataset
library(ggplot2)
filter(diamonds,carat>3)
```

3. Press Alt-Shift-K. What happens? How can you get to the same place using the menues?
Knit function works.

# Chapter 3. Data Transformation with dplyr
## Introduction

### Prerequisites
```{r Data transformation - prerequisites}
library(nycflights13)
library(tidyverse)
```

nycflights13
This data frame contains all 336,776 flights that departed from NYC in 2013. The data comes from the US Bureau of Transportation Statistics(https://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=120&Link=0).

```{r}
head(flights)
```

This data frame prints differently because it's a tibble. Tibbles are data frames, but slightly tweaked to work better in the tidyverse. 

Rows of three letter abbreviations under the columns names, which describe type of each variable.
- int: integers
- dbl: doubles (real numbers)
- chr: character vectors (strings)
- dttm: date-times (data + time)

There are other three common types of variables that aren't used in this dataset, but we will encounter in the book.
- lgl: logical vectors (T or F)
- fctr: factors (categorical variables with fixed possible values)
- date: dates

### dplyr Basics
five key dplyr functions that allow us to solve vast majority of the data manipulation challenges:
1. pick observations by their values (filter())
2. Reoder the rows (arrange)
3. Pick variables by their names (select())
4. Create new variables with functions of existing variables (mutate())
5. Collapse many variable down to a single summary (summarize())

These can all be used in conjunction with group_by(), which changes the scope of each function from operating on the entire dataset to operating on it group-by-group. 

All verbs work similarly:
1. The first argument is a data frame.
2. The subsequent arguments describe what to do with the data frame, using the variable names (without quotes)
3. The result is a new data frame

## Filter Rows with filter()
filter() allows us to subset observations based on their values.
```{r data transformation - filter()}
head(flights)

library(magrittr)
flights %>% filter(month==1,day==1) %>% head(10)
```

### Comparison 
To use filtering effectively, we have to know how to select the observations that we want using the comparison operators. R provides the standard suite: >, >=, <, <=, !=(not equal), and ==(equal).
```{r data transformation - comparison}
sqrt(2)^2==2
1/49 *49 ==1

# compute use finite precision arithmetic so remmeber that every number calculated is an approximation. Instead of relpying on ==, use near().
near(sqrt(2)^2,2)
near(1/49*49,1)
```

### Logical Operators
Multiple arguments to filter() are combined with "and": every expression must be true in order for a row to be included in the output. 
```{r filter - logical operators}
library(nycflights13)
flights %>% filter(month==11 | month==12) %>% head()
```

A useful shorthand for this problem is `x %in% y`. This will select every row where x is one of the values in y. We could use it to rewrite the preceding code: 
```{r}
nov_dec <- filter(flights,month %in% c(11,12))
head(nov_dec)
```

Sometimes we can simplify complicated subsetting by remembering De Morgan's low - !(x&y) is the same as !x |!y, and !(x|y) is the same as !x & !y. 
```{r}
flights %>% filter(arr_delay>120 |dep_delay>120) %>% head()
flights %>% filter(arr_delay<=120,dep_delay<=120) %>% head()
```

### Missing values 

One important feature of R that can make comparison tricky is missing values or NAs. NA represents an unknown values so missing values are "contagious", almost any operation involving an unknown value will also be unknown.
```{r}
NA >5
10 == NA
NA + 10
NA /2

# The most confusing result is this one:
NA==NA

# It's easiest to understand why this is true with a bit more context
x <- NA
y <- NA
x == y

# To determine if a value is missing
is.na(x)

# filter() only includes rows where the condition is true; it excludes both FALSE and NA values. If we want to preserve missing values, ask for them explicitly:
df <- tibble(x=c(1,NA,3))
filter(df,x>1)
filter(df,is.na(x)|x>1)
```

### Exercises
1. Find all flights that:
a. had an arrival delay of two or more hours
b. flew to Houston (IAH or HOU)
c. were operated by United, American or Delta
d. Departed in summer (July, August and September)
e. Arrived more than two hours late, but didn't leave late
f. Were delayed by at least an hour, but made up over 30minutes in flight
g. Departed between midngight and 6 a.m.

```{r filter() exercise}
library(nycflights13)
head(flights)
# a. arrival delay
flights %>% filter(arr_delay>=120) %>% head()
# b. flew to Houston
flights %>% filter(dest %in% c("IAH","HOU")) %>% head()
# c. operated comp
flights %>% filter(carrier %in% c("AA","DL","UA")) %>% head()
# d. seasonality
flights %>% filter(month %in% 7:9) %>% head()
# e. delay in arrival time
flights %>% filter(arr_delay >120,dep_delay<=0) %>% head()
# f. delay in arrival time
# if dep delay is 10 minutes late then arr_delay should be 10 mins lates. 10-10=0, so air time was on time. 
flights %>%  filter(dep_delay>=60,(dep_delay-arr_delay>30)) %>% head()
# g. departed between midnight and 6 am
flights %>%  filter(dep_time>=2400 | dep_time<=0600) %>% head()
```

2. Another usefuldplyr filtering helper is between(). What does it do? Can you use it to simplify the code needed to answer the previous challenges?
```{r between()}
filter(flights,between(dep_time,601,2359)) %>% head()
```

3. How many flights have a missing de_time? What other variables are missing? What might these row reporesent?
```{r filter - NA values}
# missmap package
library(Amelia)
missmap(flights)

# missing value calculation
sum(is.na(flights$dep_time))
map_dbl(flights,~sum(is.na(.x)))
```

4. Why is NA^0 not missing? Why is NA|TRUE not missing? Why is FALSE & NA not missing? Can you figure out the general rule? 
Because anything is `^0` equals `1`. Because NA|TRUE is saying whether one of the two is TRUE and the second one is. Because at least one of the two expressions can be tested: FALSE&NA.In NA&NA neither can be tested and the results is `NA&NA`. 

The general rule is that whenever there is a logical expressions, if one can be tested, then the results shouldn't be `NA`. And any operation that the results is determined, regardless of the number, the inputting `NA` does not affect the result.

## Arrange Rows with arrange()
arrange() works similarly to filter() except that instead of selecting rows, it changes their order. It takes a data frame and a set of column names (or more complicated expressions) to order by. 

If we provide more than one column name, each additional column will be used to break ties in the values of preceding columns:
```{r arrange()}
flights %>% arrange(year,month,day) %>% head(10)
```

Use desc() to reorder by a column in descending order:
```{r arrange() - desc}
flights %>% arrange(desc(arr_delay)) %>% head()
```

Missing values are always sorted at the end:
```{r}
df <- tibble(x=c(5,2,NA))
arrange(df,x)
arrange(df,desc(x))
```

## Exercise
1. How could you use arrange() to sort all missing values to the start?
```{r}
# arrange exercise 1 ----
library(tidyverse)
df <- tibble(x=c(5,2,NA),
             y=c(2,NA,2))
rowSums(df)
arrange(df)
arrange(df,desc(is.na(x)))
```

We're basically saying, those which are `TRUE` to being `NA`, sort othem in descending order. 

2. Sort flights to find the most delayed flights. Find the flights that left earliest. 
```{r}
# arrange exercise 2 ----
library(nycflights13)
head(flights)
arrange(flights,dep_delay) %>% head()
arrange(flights,desc(dep_delay)) %>% head()
```

3. Sort flights to find the fastest flights.
```{r}
# arrange exercise 3  ----
arrange(flights,air_time) %>% head()
```

4. Which flights traveled the longest? Which traveled the shortest?
```{r}
# arrange() exercise 4 ----
# shortest
flights %>% 
  arrange(air_time) %>% 
  select(carrier,flight,air_time)
# fastest
flights %>% 
  arrange(-air_time) %>% 
  select(carrier,flight,air_time)
```

## Select Columns with select()

It's not uncommon to get datasets with hundreds or even thousands of variables. In this case, the first challenge is often narrowing in on the variables we're actually intersted in. 

select() allows us to rapidly zoon in on a useful subset using operations based on the names of the variables. 
```{r}
# select columns by name
select(flights,year,month,day)
# select all columns between year and day
select(flights,year:day)
# select all columns except those from year to day 
select(flights,-(year:day))
```

There are number of helper functions we can use within select():
- starts_with("abc"):matches names that begin with "abc"
- ends_with("xyz"): matches names that end with "xyz"
- contains("ijk"): matches names that end with "xyz"
- matches("(.)\\1"):selects variables that match a regular expression. This only matches any variable that contain repeated characters. 
- num_range("x",1:3): matches x1, x2 and x3.

select() can be used to rename variables, but it's rearely useful because it drops all of the variable not explitly mentioned. Instead, rename(), which is a variant of select() that keeps all the variables that aren't explicitly mentioned. 

```{r}
# select() - rename function ----
rename(flights,tail_num=tailnum) %>% head()
select(flights, time_hour,air_time,everything())
```

### Exercises
1. Brainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights.
```{r}
# select() - exercise
vars <- c('dep_time','dep_delay','arr_time','arr_delay')
select(flights,vars)
select(flights,matches('^dep|^arr'))

```

2. What happens if we include the name of a variable muptile times in a select call?
2
```{r}
select(flights,dep_time,dep_time)
# nothing, it just returns it one
```

3. What does the one_of() function do? Why might it be helpful in conjunction with this vector? 
- It works because select only accept variable names without `""` quotes. By including inside `one_of`, one can use character names. 
```{r}
vars <- c("year","month","day","dep_delay","arr_delay")
select(flights,one_of(vars))
```

4. Does the result of running the following code surprise us? How do the select helpers deal with case by default? How can you change that default?
```{r}
select(flights,contains("TIME",ignore.case=F))
```

## Add New Variables with mutate()
Besides selecting sets of existing columns, it's often useful to add new columns that are functions of existing columns. mutate() always adds new columns at the end of the dataset, so we will start by creating a narrower dataset so we can see the new variables. 
```{r}
# mutate() --------
flights_sml <- select(flights,year:day,
                      ends_with('delay'),
                      distance,
                      air_time)

# mutate function
mutate(flights_sml,
       gain=arr_delay-dep_delay,
       speed=distance/air_time*60)
```

Note that we can refer to columns that we have just created:
```{r}
# mutate() part2
mutate(flights_sml,
       gain=arr_delay-dep_delay,
       hours=air_time/60,
       gain_per_hour=gain/hours)
```

If we only want to keep the new variables, use transmute():
```{r}
transmute(flights,
          gain=arr_delay-dep_delay,
          hours=air_time/60,
          gain_per_hour=gain/hours)
```

### Useful Creation Functions
There are many functions for creating new variables that we can use with mutate(). The key property is that the function must be vectorized. It must take a vector of values as input, and returns a vector with the same number of values as output. 

1. Arithmetic operators +,-,*,/,^

2. Modular arithmetic %/%, %%
- %/% integer devision
- %% remainder, where 
x == y*(x%/%y)+(x%%y)
```{r}
transmute(flights, dep_time,
          hour=dep_time %/% 100,
          minute=dep_time %% 100)
```

3. Logs log(), log2(), log10()
4. offsets
- lead() and lag() allow us to refer to leading or lagging values. This allows us to compute running differences (x-lag(x)). They are most useful in conjunction with group_by().
```{r}
# lag(), lead() ---------
x <- 1:10
lag(x)
lead(x)
```

5. Cumulative and rolling aggregates
R provides functions fo running sums, products, mis and maxes:
cumsum(), cumprod(), cummin(), cummax(); and dplyer provides cummean() for cumulative means. 
```{r}
# cumsum, cummean --------
x
cumsum(x)
cummean(x)
```

6. Logicl comparisons <, <=, >, >=, !=
IF we are doing a complex sequence of logical operations, it's often a good idea to store the interim values in new variables so we can check that each step is working as expected.

7. Ranking
There are a number of ranking functions, but we should start with min_rank(). It does the most usual type of ranking, and the default gives the smallest values the smallest ranks.
```{r}
y <- c(1,2,2,NA,3,4)
min_rank(y)
min_rank(desc(y))
```

If min_rank() doesn't do what we need,look at the variants
- row_number()
- dense_rank()
- percent_rank()
- cume_dist()
- ntile()
```{r}
row_number(y)
dense_rank(y)
percent_rank(y)
cume_dist(y)
```

### mutate() exercise
1. Currently dep_time and sched_dep_time are convenient to look at, but hard to compute with because they're not really continuous numbers. Convert them to a more convenient representation of number of minutes since midnight. 
```{r}
head(flights)
mutate(flights, 
       dep_hour = dep_time %/% 100,
       de_minutes = dep_time %% 100)

hours2mins <- function(x){
  x%/% 100*60 + x%%100}

# with integer division
mutate(flights,
       dep_time=hours2mins(dep_time),
       sched_dep_time=hours2mins(sched_dep_time))

# with rounding operations
mutate(flights,
       dep_time=60*floor(dep_time/100)+(dep_time-floor(dep_time/100)*100),
       sched_dep_time=60*floor(sched_dep_time/100)+(sched_dep_time-floor(sched_dep_time/100)*100))
```

2. Compare air_time with arr_time-dep_time. What do you expect to see? What do you see? What do you need to do to fix it?
```{r}
flights %>% 
  mutate(dep_time = (dep_time %/% 100) * 60 + (dep_time %% 100),
         sched_dep_time = (sched_dep_time %/% 100) * 60 + (sched_dep_time %% 100),
         arr_time = (arr_time %/% 100) * 60 + (arr_time %% 100),
         sched_arr_time = (sched_arr_time %/% 100) * 60 + (sched_arr_time %% 100)) %>%
  transmute((arr_time - dep_time) %% (60*24) - air_time)
```

3. Compare dep_time, sched_dep_time, and dep_delay. How would we expect those three numbers to be related? 
```{r}
hours2mins <- function(x){
  x%/%100*60 + x%%100
}

# dep_time-shed_dep_time
select(flights,contains("dep")) %>% 
  mutate(dep_time_two=hours2mins(dep_time)-hours2mins(sched_dep_time))

## those two numbers don't match because we aren't accounting for flights
## where the departure time is the next dat from the scheduled departure time.

# 
select(flights,contains("dep")) %>% 
  mutate(dep_time_two=hours2mins(dep_time)-hours2mins(sched_dep_time)) %>% filter(dep_delay!=dep_time_two) %>% 
  mutate(dep_time_two=hours2mins(dep_time)-hours2mins(sched_dep_time-2400))
# there it is fixed
```

4. Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for min_rank()
```{r}
flights %>% 
  filter(min_rank(-(dep_delay)) %in% 1:10)

flights %>% 
  top_n(10,dep_delay)
```

5. What does 1:3 + 1:10 return? Why?
```{r}
x <- c(2,4,6,5,7,9,8,10,12,11)
p <- 1:3+1:10
p==x
```


## Grouped Summaries with summarize()

The last key verb is summarize(). It collapses a data frame to a single row: 
```{r}
# summarize() -------
library(dplyr)
library(nycflights13)
summarize(flights,delay=mean(dep_delay,na.rm = T))
```

Summarize() is not terribly useful unless we pair it with group_by(). This changes the unit of analysis from the complete dataset to individual groups. 

Then, when we use the dplyr verbs on a grouped data frame, they will be automatically applied "by group". For example, if we applied exactly the same code to a data frame grouped by date, we get the average delay per date. 
```{r}
by_day <- group_by(flights, year,month,day)
head(by_date)

summarize(by_day,delay=mean(dep_delay,na.rm = T))
```

Together group_by() and summarize() provide one of the tools that you'll use most commonly when working with dplyr:grouped summaries. 

### Combining multiple operations with pipe

When we want to explore the relationship between the distance and average delay for each location. Using what we know about dployr we can write code like this with pipe operator
```{r}

library(magrittr)

by_dest <- flights %>% group_by(dest) 
delay <- summarize(by_dest,
                   count=n(),
                   dist=mean(distance,na.rm = T),
                   delay=mean(arr_delay,na.rm = T))
delay <- filter(delay,count>20,dest!="HNL")

# visualization
library(ggplot2)
ggplot(delay,mapping=aes(x=dist,y=delay))+
  geom_point(aes(size=count),
             alpha=0.3)+
  geom_smooth(se=F)
```

There are three steps to prepare this data:
1. Group flights by destination
2. Summarize to compute distance, average delay, and number of flights
3. Filter to remove noisy points aqnd Honolulu airport, which is almost twice as far aay as the next closest airport

This code is little frustrating to write because we have to give each intermediate data frame a name, even thought we don't care about it.

There is another way to To tackle this problem with the pipe %>%, 
```{r}
# pipe operator -----
delays <- flights %>% 
  group_by(dest) %>% 
  summarize(
    count=n(),
    dist=mean(distance,na.rm=T),
    delay=mean(arr_delay,na.rm=T))
      filter(count>20,dest!="HNL")
head(delays)

```

### Missing values 
We may have wondered the na.rm rgument we used earier.
What happens if we don't set it.
-> we get a lot of missing values. 

The reason is that aggregation functions obey the usual rule of missing values: if there is any missing value in the input, the output will be a missing vlue as well. 

```{r}
# na.rm() argument chunk 1 -----
flights %>% 
  group_by(year,month,day) %>% 
  summarize(mean=mean(dep_delay))
```

Fortunately, all aggregation functions have an na.rm argument, which removes the missing values prior to computation.
```{r}
# na.rm() argument chunk 2 -----
flights %>% 
  group_by(year,month,day) %>% 
  summarize(mean=mean(dep_delay,na.rm=T))
```

In this case, where missing values represent cancelled flights, we could als tackle the problem by first removing the cancelled fligts. We'll save this dataset so we can reuse it in the next few examples:
```{r}
library(Amelia)
missmap(flights)
not_cancelled <- flights %>% 
  filter(!is.na(dep_delay),!is.na(arr_delay))

missmap(not_cancelled)

not_cancelled %>% 
  group_by(year,month,day) %>% 
  summarize(mean=mean(dep_delay))
```

### Counts
Whenever we do any agregation, its always a good idea to include either count(n()) or a count of nonmissing values, sum(!is.na(x)). 
```{r}
# counts() -----
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarize(
    delay=mean(arr_delay)
  )

ggplot(delays, aes(x=delay))+
  geom_freqpoly(binwidth=10)
```

We can get more inslights if we draw a scatterplot of number of flights versus average delay:
```{r}
# count() part 2 -----
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarize(
    delay=mean(arr_delay,na.rm=T),
    n=n()
  )
head(flights)
head(delays)
ggplot(delays,aes(x=n,y=delay))+
  geom_point(alpha=1/10)
```

Not surprisingly, there is much greater variation in the average delay when there are few flights. The shape of this plot is very characteristic: Whenever we plot a mean versus group size, we'll see that the variation decreases as the sample size increases. 
```{r}
# count() part 3 -----
delays %>% 
  filter(n>25) %>% 
  ggplot(mapping=aes(x=n,y=delay))+
  geom_point(alpha=1/10)
```

There is another common variation of this type of pattern. Here we use data from the Lahman package to compute the batting average(number of hits/number of attemps) of every major league baseball player.

When we plot the skill of the batter against the number of opportnuties to hit the ball, we see two patterns:
- As above, the variation in our aggregate decreases as we get more data points
- There is a positive correlation between skill and opportunities to hit the ball. This is because teams control who gets to play, and obviously they'll pick their best players:
```{r}
# count part 4 -----
# convert to a tible it prints nicely

 # install.packages("Lahman")
library(Lahman)

batting <- 
  as_tibble(Lahman::Batting)

head(batting)

batter <- batting %>% 
  group_by(playerID) %>% 
  summarize(
    ba=sum(H,na.rm = TRUE)/sum(AB,na.rm = TRUE),
    ab=sum(AB,na.rm = TRUE)
  )

batter %>% 
  filter(ab>100) %>% 
  ggplot(aes(x=ab,y=ba))+geom_point(alpha=0.1)+geom_smooth(se=FALSE)
```

This also has important implications for ranking. If we naively sort on desc(ba), the people with the best batting averages are clearly lucky, not skilled. 
```{r}
# count part 5 -----
batter %>% arrange(desc(ba)) %>% head(20)
```

### Useful Summary Functions
Just using means, counts, and sum can get usa long way, but R provides many other useful summary functions:

#### Measures of location

#### Measures of spead

#### Measures of rank 


## Grouped Mutates (and filters)







